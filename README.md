# ğŸ§  ML Sensei LoRA

A small LoRA fine-tune that turns a base LLM into a **clear, structured explainer** for ML / LLM / systems conceptsâ€”written in a documentation-style tone.

This repo contains:

- ğŸ—‚ A curated **instruction dataset** (`train.jsonl`, `eval.jsonl`)
- ğŸ§ª A **LoRA training script** using PEFT + Transformers
- ğŸ“Š A **side-by-side eval script** for base vs LoRA
- ğŸ“¦ Config + requirements for full reproducibility

---

## ğŸ¯ Goal

Create a lightweight adapter that makes a small chat LLM:

- Explain ML concepts clearly and patiently  
- Use headings, bullet points, and analogies  
- Aim at junior developers and technical writers  

---

## ğŸ—ï¸ Project structure

```text
ml-sensei-lora/
â”œâ”€ README.md
â”œâ”€ config.yaml
â”œâ”€ requirements.txt
â”œâ”€ train_lora.py
â”œâ”€ evaluate_lora.py
â””â”€ data/
   â”œâ”€ train.jsonl
   â””â”€ eval.jsonl
